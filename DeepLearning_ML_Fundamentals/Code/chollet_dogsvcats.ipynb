{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\"\"\"\n",
    "    author: William Darko (repurposed from original author Francois Chollet)\n",
    "    date: July, 2021\n",
    "    description: Basic ConvNet example using kaggle dogs vs cats dataset from dogs vs cats comeptition\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizer_v2 as optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# copying images into training, validation and test directories\n",
    "\n",
    "init_train_dataset_dir = '../../datasets/catsvdogs_train'\n",
    "init_test_dataset_dir = '../../datasets/catsvdogs_test'\n",
    "base_dataset_dir = '../../datasets/smaller_datasets'\n",
    "\n",
    "# create directories for training, testing, and validation data\n",
    "train_dir = os.path.join(base_dataset_dir, 'catsvdogs_train_dir')\n",
    "validation_dir = os.path.join(base_dataset_dir, 'catsvdogs_valid_dir')\n",
    "test_dir = os.path.join(base_dataset_dir, 'catsvdogs_test_dir')\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(validation_dir)\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "\n",
    "# create sub training, validation, and testing directories for both cat and dog\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "\n",
    "os.mkdir(train_cats_dir)\n",
    "os.mkdir(validation_cats_dir)\n",
    "os.mkdir(test_cats_dir)\n",
    "os.mkdir(train_dogs_dir)\n",
    "os.mkdir(validation_dogs_dir)\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "# create cats training, validation, and test dataset\n",
    "# first 1000 cat images of file name 'cat.{i}.jpg'\n",
    "file_names = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in file_names:\n",
    "    src = os.path.join(init_train_dataset_dir, fname)\n",
    "    dest = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "file_names = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in file_names:\n",
    "    src = os.path.join(init_train_dataset_dir, fname)\n",
    "    dest = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "file_names = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in file_names:\n",
    "    src = os.path.join(init_train_dataset_dir, fname)\n",
    "    dest = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "# partition data into dogs training, validation, and test directories\n",
    "file_names = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in file_names:\n",
    "    src = os.path.join(init_train_dataset_dir, fname)\n",
    "    dest = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "file_names = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in file_names:\n",
    "    src = os.path.join(init_train_dataset_dir, fname)\n",
    "    dest = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "file_names = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in file_names:\n",
    "    src = os.path.join(init_train_dataset_dir, fname)\n",
    "    dest = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "# sanity check\n",
    "\n",
    "print(\"TOTAL CATS DATA COUNT \\n TRAINING: {}, VALIDATION: {}, TESTING: {} \\n\".format(len(os.listdir(train_cats_dir)), len(os.listdir(validation_cats_dir)), \n",
    "len(os.listdir(test_cats_dir))))\n",
    "\n",
    "print(\"TOTAL DOGS DATA COUNT \\n TRAINING: {}, VALIDATION: {}, TESTING: {}\".format(len(os.listdir(train_dogs_dir)), len(os.listdir(validation_dogs_dir)), \n",
    "len(os.listdir(test_dogs_dir))))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# defining the model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# configuring the model for training, and preprocessing step\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.rmsprop.RMSProp(learning_rate=1e-4), metrics=['acc'])\n",
    "\n",
    "\"\"\"\n",
    "because our training and testing data are still just jpeg files on disk, we must make them floating point tensors before feeding them into the\n",
    "convnets\n",
    "\"\"\"\n",
    "# preprocessing steps:\n",
    "# read image files\n",
    "# decode jpeg into rgb grids of pixels\n",
    "# convert into floating point tensors\n",
    "# rescale pixel values to [0,1] interval (preferable for neural networks)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=20, class_mode='binary')\n",
    "validation_data_generator = test_datagen.flow_from_directory(validation_dir, target_size=(150,150), batch_size=20,class_mode='binary')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('ai': conda)"
  },
  "interpreter": {
   "hash": "ebce0c7dac342d90580125ce713960370f01d7bc21030aebdc37b54c0352bd57"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}