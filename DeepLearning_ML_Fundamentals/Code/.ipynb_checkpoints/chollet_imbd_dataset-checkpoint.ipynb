{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "author: William Darko (repurposed from original author Francois Chollet)\n",
    "date: June, 2021\n",
    "description: Two-class (binary) classification using IMDB dataset to classify movie review as positive or negative. The original code sample\n",
    "is provided by Francois Chollet in his 'Deep Learning with Python' (1st Edition, Manning publisher)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williammatrix/opt/anaconda3/envs/ai/lib/python3.9/site-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/williammatrix/opt/anaconda3/envs/ai/lib/python3.9/site-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# loading the IMBD dataset\n",
    "\n",
    "(training_data, training_labels), (testing_data, testing_labels) = imdb.load_data(num_words=10000)\n",
    "# num_words argument denotes taking the top 10000 most frequent words in the training_data\n",
    "# training_data, and testing_data are list of reviews where each review is a list of word indices like [1, 14, 28, 99, 299, 87...] from a dictionary of words\n",
    "# thus the first word in a review [1, 14, 28, 99, 299, 87...], the word at index 0 of the review, is the word at index 1 of the dictionary.\n",
    "# training_labels and testing_labels are list of 1s and 0s classifying a word as positive, or negative, respectively\n",
    "\n",
    "print(training_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data\n",
    "\n",
    "# one way is to pad the lists to the same length and turn them into integer tensors of shape (samples, word_indices) and use Embedding as the first layer\n",
    "# other way is to 'One-hot' encode lists, meaning to turn them into vectors of 0s and 1s where 0 denotes no presense of that letter and 1 the opposite\n",
    "# using One-hot encoding we create a list of length 10000 where there are 0s every where except for the indices which corresponding letters appear in the review sequence\n",
    "\n",
    "def encode_sequences(sequences, dimesion=10000):\n",
    "    results =  np.zeros((len(sequences),dimesion))\n",
    "    for i, review in enumerate(sequences):\n",
    "        results[i, review] = 1 # equivalent of iterating a through review with a second counter j, and doing results[i][j] = 1\n",
    "    return results\n",
    "\n",
    "x_train_data = encode_sequences(training_data)\n",
    "x_test_data = encode_sequences(testing_data)\n",
    "\n",
    "y_train_labels = np.asarray(training_labels, dtype=np.float32)\n",
    "y_test_labels = np.asarray(testing_labels, dtype=np.float32)\n",
    "\n",
    "print(\"Training Data: \", x_train_data)\n",
    "print(\"Training Labels: \", y_train_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
